{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23a8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7e8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the file\n",
    "path = pathlib.Path(\"data/JSONS\")\n",
    "spell_path = path / \"spells_pdf.json\"\n",
    "weapon_path = path / \"weapons_pdf.json\"\n",
    "feats_path = path / \"feats_pdf.json\"\n",
    "class_path = path / \"classes_pdf.json\"\n",
    "\n",
    "\n",
    "spells = json.loads(spell_path.read_text())  # <-- use plural; expect a\n",
    "weapons = json.loads(weapon_path.read_text())  # <-- use plural; expect a list of dicts\n",
    "feats = json.loads(feats_path.read_text()) \n",
    "classes =json.loads(class_path.read_text())  \n",
    "\n",
    "# # 2. Flatten each spell record into a plain-text blob\n",
    "# def record_to_text(rec: dict, rec_type: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Turn a dict into a multi-line string.\n",
    "#     Keeps the large description under the 'desc' or 'description' key.\n",
    "#     \"\"\"\n",
    "#     lines = [f\"type: {rec_type}\"]\n",
    "#     for k, v in rec.items():\n",
    "#         # Prefer a single key name for description so we don't embed it twice\n",
    "#         if k in {\"desc\", \"description\"}:\n",
    "#             lines.append(f\"description: {v}\")\n",
    "#         else:\n",
    "#             lines.append(f\"{k}: {v}\")\n",
    "#     return \"\\n\".join(lines)\n",
    "\n",
    "def clean_record(rec: dict, rec_type: str = \"record\") -> str:\n",
    "    \"\"\"\n",
    "    Clean and format a record into a human-readable, embedding-friendly string.\n",
    "    Ensures 'description' is included (normalizes 'desc'), preserves key ordering,\n",
    "    and includes extra requested fields.\n",
    "    \"\"\"\n",
    "    # Normalize desc → description\n",
    "    if \"desc\" in rec and \"description\" not in rec:\n",
    "        rec[\"description\"] = rec.pop(\"desc\")\n",
    "\n",
    "    # Fields to include in this preferred order\n",
    "    priority_keys = [\n",
    "        \"name\", \"description\", \"school\", \"level\", \"spell_level\", \"level_int\", \"page\",\n",
    "        \"casting_time\", \"range\", \"components\", \"material\", \"duration\", \"concentration\",\n",
    "        \"ritual\", \"dnd_class\", \"spell_lists\", \"archetype\", \"circles\"\n",
    "    ]\n",
    "\n",
    "    # Fields to exclude entirely\n",
    "    exclude_keys = {\n",
    "        \"slug\", \"document__url\", \"document__title\", \"document__license_url\",\n",
    "        \"target_range_sort\", \"document__slug\"\n",
    "    }\n",
    "\n",
    "    def format_value(v):\n",
    "        if isinstance(v, bool):\n",
    "            return \"yes\" if v else \"no\"\n",
    "        elif isinstance(v, list):\n",
    "            return \", \".join(str(i) for i in v)\n",
    "        return str(v)\n",
    "\n",
    "    lines = [f\"type: {rec_type}\"]\n",
    "\n",
    "    # Add fields in preferred order\n",
    "    for key in priority_keys:\n",
    "        if key in rec and key not in exclude_keys:\n",
    "            val = rec[key]\n",
    "            if val not in (None, \"\"):\n",
    "                lines.append(f\"{key}: {format_value(val)}\")\n",
    "\n",
    "    # Add any remaining keys not already included or excluded\n",
    "    for key, val in rec.items():\n",
    "        if key not in priority_keys and key not in exclude_keys:\n",
    "            if val not in (None, \"\"):\n",
    "                lines.append(f\"{key}: {format_value(val)}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# docs   = [record_to_text(r, \"spell\")  for r in spells] + \\\n",
    "#          [record_to_text(r, \"weapon\") for r in weapons]+ \\\n",
    "#          [record_to_text(r, \"feats\") for r in feats]+ \\\n",
    "#          [record_to_text(r, \"classes\") for r in classes]\n",
    "\n",
    "docs = [clean_record(s, \"spell\")   for s in spells] + \\\n",
    "       [clean_record(w, \"weapon\")  for w in weapons] + \\\n",
    "       [clean_record(f, \"feat\")    for f in feats] + \\\n",
    "       [clean_record(c, \"class\")   for c in classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302531c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs embedded: 324\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total docs embedded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec1303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type: spell\\nname: Aid\\ndescription: Your spell bolsters your allies with toughness and \\nresolve. C hoose up to three creatures within range.\\nEach target’s hit point maximum and current hit points \\nincrease by 5 for the duration.\\nAt Higher Levels. W hen you cast this spell using \\na spell slot of 3rd level or higher, a target’s hit points \\nincrease by an additional 5 for each slot level above 2nd.\\nschool: abjuration\\nlevel: 2nd-level\\ncasting_time: 1 action\\nrange: 30 feet\\ncomponents: V, S, M (a tiny strip o f white cloth)\\nduration: 8 hours']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f639ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.12/site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.54.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (0.34.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1708953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c388d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embs = embedder.encode(docs, batch_size=64, convert_to_numpy=True)\n",
    "index = faiss.IndexFlatL2(embs.shape[1])\n",
    "index.add(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dccc0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(question: str, k: int = 5):\n",
    "    q_emb = embedder.encode([question]).astype(\"float32\")\n",
    "    D, I = index.search(q_emb, k)                # distances & indices\n",
    "    hits = [docs[i] for i in I[0]]\n",
    "    return \"\\n\\n\".join(hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbeccdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"   # any small instruct model works\n",
    "tok  = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "llm  = pipeline(\"text-generation\",\n",
    "                model=model_name,\n",
    "                tokenizer=tok,\n",
    "                device=\"cpu\",            # change to 0 if you have a GPU\n",
    "                max_new_tokens=100,\n",
    "                temperature=.01)         # deterministic\n",
    "\n",
    "def answer(question: str):\n",
    "    context = retrieve(question, k=2)\n",
    "    prompt = f\"\"\"You are a helpful assistant. \n",
    "    Answer the question using only the context below. \n",
    "    If the answer is not in the context, say you don't know.\n",
    "\n",
    "    ### Context\n",
    "    {context}\n",
    "\n",
    "    ### Question\n",
    "    {question}\n",
    "\n",
    "    ### Answer\n",
    "    \"\"\"\n",
    "    resp = llm(prompt)[0][\"generated_text\"]\n",
    "    return resp.split(\"### Answer\",1)[-1].strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8780187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can tell you about the spell acid splash. It is a spell that creates a small, acidic mist that can be used to damage or daze enemies. The spell is typically cast on a target that is within 120 feet of the caster. The mist is created by pouring a small amount of acid into a container, such as a flask or a bottle. The container is then placed in the spell's focus, which is usually a\n"
     ]
    }
   ],
   "source": [
    "print(answer(\"can you tel me about the spell acid splash and where you got this information?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4298cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer(\"what is the damage of a longsword?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3674aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Druid: Sure, I'd be happy to help you. Augury is a spell that allows you to detect the presence of spirits, animals, and other supernatural beings. It's a powerful tool for divination, but it's also dangerous if you're not careful. Here's how to cast it:\n",
      "\n",
      "    1. Choose a location where you'll be casting the spell. This could be a clearing, a forest, or\n"
     ]
    }
   ],
   "source": [
    "print(answer(\"Im not sure what spells to cast, I'm a druid, can you help me?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "920e4de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Lance\n",
      "    2. Spear\n",
      "    3. Sword\n",
      "    4. Dagger\n",
      "    5. Mace\n",
      "    6. Quarterstaff\n",
      "    7. Sling\n",
      "    8. Spear\n",
      "    9. Dagger\n",
      "    10. Mace\n",
      "    11. Quarterstaff\n",
      "    12. Sling\n",
      "    13. Spear\n",
      "    14. Dagger\n",
      "    15. Mace\n"
     ]
    }
   ],
   "source": [
    "print(answer(\"what weapons can a druid use?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e40c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A feat is a special ability that grants a bonus to a character's ability score.\n",
      "    2. A feat is a special ability that grants a bonus to a character's proficiency in a skill or tool.\n",
      "    3. A feat is a special ability that grants a bonus to a character's proficiency in a language or code.\n"
     ]
    }
   ],
   "source": [
    "print(answer('what is a feat?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c79e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# import json\n",
    "# import pathlib\n",
    "# import pandas as pd\n",
    "\n",
    "# # %%\n",
    "# # 1. Load the file\n",
    "# path = pathlib.Path(\"data\")\n",
    "# spell_path = path / \"spells.json\"\n",
    "# weapon_path = path / \"weapons.json\"\n",
    "\n",
    "# spells = json.loads(spell_path.read_text())\n",
    "# weapons = json.loads(weapon_path.read_text())\n",
    "\n",
    "# # 2. Flatten each spell/weapon into a text blob\n",
    "# def record_to_text(rec: dict, rec_type: str) -> str:\n",
    "#     lines = [f\"type: {rec_type}\"]\n",
    "#     for k, v in rec.items():\n",
    "#         if k in {\"desc\", \"description\"}:\n",
    "#             lines.append(f\"description: {v}\")\n",
    "#         else:\n",
    "#             lines.append(f\"{k}: {v}\")\n",
    "#     return \"\\n\".join(lines)\n",
    "\n",
    "# docs = [record_to_text(r, \"spell\") for r in spells] + \\\n",
    "#        [record_to_text(r, \"weapon\") for r in weapons]\n",
    "\n",
    "# print(f\"Total docs embedded: {len(docs)}\")\n",
    "\n",
    "# # %%\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import hnswlib\n",
    "# import numpy as np\n",
    "\n",
    "# # %%\n",
    "# embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embs = embedder.encode(docs, batch_size=64, convert_to_numpy=True).astype(\"float32\")\n",
    "\n",
    "# dim = embs.shape[1]\n",
    "# index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "# index.init_index(max_elements=len(docs), ef_construction=200, M=16)\n",
    "# index.add_items(embs)\n",
    "\n",
    "# # Save index and doc IDs\n",
    "# index.save_index(\"data/spell_weapon.index\")\n",
    "# np.save(\"data/spell_weapon.embeddings.npy\", np.arange(len(docs)))\n",
    "\n",
    "# # %%\n",
    "# def retrieve(question: str, k: int = 5):\n",
    "#     q_emb = embedder.encode([question], convert_to_numpy=True).astype(\"float32\")\n",
    "#     labels, distances = index.knn_query(q_emb, k=k)\n",
    "#     return \"\\n\\n\".join(docs[i] for i in labels[0])\n",
    "\n",
    "# # %%\n",
    "# from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# llm = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_name,\n",
    "#     tokenizer=tok,\n",
    "#     device=\"cpu\",  # change to 0 if you have GPU\n",
    "#     max_new_tokens=128,\n",
    "#     temperature=0.0\n",
    "# )\n",
    "\n",
    "# def answer(question: str):\n",
    "#     context = retrieve(question, k=2)\n",
    "#     prompt = f\"\"\"You are a helpful assistant. \n",
    "# Answer the question using only the context below. \n",
    "# If the answer is not in the context, say you don't know.\n",
    "\n",
    "# ### Context\n",
    "# {context}\n",
    "\n",
    "# ### Question\n",
    "# {question}\n",
    "\n",
    "# ### Answer\n",
    "# \"\"\"\n",
    "#     resp = llm(prompt)[0][\"generated_text\"]\n",
    "#     return resp.split(\"### Answer\", 1)[-1].strip()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
